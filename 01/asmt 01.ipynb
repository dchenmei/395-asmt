{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> I. Decision Tree </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) $ (x_{1} \\land x_{2}) \\lor (x_{1} \\land x_{3}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"a.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) $ (x_{1} \\land x_{2})$ xor $ x_{3} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"b.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) $ \\neg A \\lor \\neg B \\lor \\neg C \\lor \\neg D $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"c.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) A breakdown of the features reveal:\n",
    "    <ul>\n",
    "    <li> label is binary </li>\n",
    "    <li> two binary features </li>\n",
    "    <li> one feature with three possible values </li>\n",
    "    <li> one feature with four possible values </li>\n",
    "    </ul> \n",
    "Then to compute all possible functions (computed in Python snippet):  \n",
    "$ 2^{2^{2} + 3^{1} + 4^{1}} $\n",
    "\n",
    "Because the training data set only has nine examples, only nine functions are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Functions: 2048\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible Functions:\", 2**(4 + 3 + 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) $ Entropy(S) = H(S) = -p_{+} \\log(p_{+}) - p_{-} \\log(p_{-}) $  \n",
    "Note: computation is done through Python snippet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technology $ H(No) = \\frac{-4}{6}log_{2}(\\frac{4}{6}) - \\frac{2}{6}log_{2}(\\frac{2}{6})\\\\ \n",
    "           H(Yes) = \\frac{-1}{3}log_{2}(\\frac{1}{3}) - \\frac{2}{3}log_{2}(\\frac{2}{3})\\\\\n",
    "           H(Technology) = \\frac{6}{9}H(No) + \\frac{3}{9}H(Yes)$\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(No) 0.9182958340544896\n",
      "H(Yes) 0.9182958340544896\n",
      "H(Technology) 0.9182958340544896\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "h_no = (-4/6 * math.log(4/6, 2)) - (2/6 * math.log(2/6, 2))\n",
    "h_yes = (-1/3 * math.log(1/3, 2)) - (2/3 * math.log(2/3, 2))\n",
    "h_tech = (6/9 * h_no) + (3/9 * h_yes)\n",
    "print(\"H(No)\", h_no)\n",
    "print(\"H(Yes)\", h_yes)\n",
    "print(\"H(Technology)\", h_tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment $ H(No) = \\frac{-1}{4}log_{2}(\\frac{1}{4}) - \\frac{3}{4}log_{2}(\\frac{3}{4})\\\\ \n",
    "              H(Yes) = \\frac{-4}{5}log_{2}(\\frac{4}{5}) - \\frac{1}{5}log_{2}(\\frac{1}{5})\\\\\n",
    "              H(Environment) = \\frac{4}{9}H(No) + \\frac{5}{9}H(Yes)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(No) 0.8112781244591328\n",
      "H(Yes) 0.7219280948873623\n",
      "H(Environment) 0.9182958340544896\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "h_no = (-1/4 * math.log(1/4, 2)) - (3/4 * math.log(3/4, 2))\n",
    "h_yes = (-4/5 * math.log(4/5, 2)) - (1/5 * math.log(1/5, 2))\n",
    "h_env = (4/9 * h_no) + (5/9 * h_yes)\n",
    "print(\"H(No)\", h_no)\n",
    "print(\"H(Yes)\", h_yes)\n",
    "print(\"H(Environment)\", h_tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human $ H(Not Care) = \\frac{-4}{4}log_{2}(\\frac{4}{4}) - \\frac{0}{4}log_{2}(\\frac{0}{4})\\\\ \n",
    "         H(Like) = \\frac{-1}{4}log_{2}(\\frac{1}{4}) - \\frac{3}{4}log_{2}(\\frac{3}{4})\\\\\n",
    "         H(Hate) = \\frac{-0}{1} log_{2}(\\frac{0}{1}) - \\frac{1}{1} log_{2}(\\frac{1}{1})\\\\\n",
    "         H(Human) = \\frac{4}{9}H(Not Care) + \\frac{4}{9}H(Like) + \\frac{1}{9}H(Hate)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(Not Care) 0\n",
      "H(Like) 0.8112781244591328\n",
      "H(Hate) 0\n",
      "H(Human) 0.3605680553151701\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "h_not_care = 0\n",
    "h_like = (-1/4 * math.log(1/4, 2)) - (3/4 * math.log(3/4, 2))\n",
    "h_hate = 0\n",
    "h_human = (4/9 * h_not_care) + (4/9 * h_like) + (1/9 * h_hate)\n",
    "\n",
    "print(\"H(Not Care)\", h_not_care)\n",
    "print(\"H(Like)\", h_like)\n",
    "print(\"H(Hate)\", h_hate)\n",
    "print(\"H(Human)\", h_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance $ H(1) = \\frac{-1}{2}log_{2}(\\frac{1}{2}) - \\frac{1}{2}log_{2}(\\frac{1}{2})\\\\ \n",
    "           H(2) = \\frac{-1}{1}log_{2}(\\frac{1}{1}) - \\frac{0}{1}log_{2}(\\frac{0}{1})\\\\\n",
    "           H(3) = \\frac{-2}{3} log_{2}(\\frac{2}{3}) - \\frac{1}{3} log_{2}(\\frac{1}{3})\\\\\n",
    "           H(4) = \\frac{-1}{3} log_{2}(\\frac{1}{3}) - \\frac{2}{3} log_{2}(\\frac{2}{3})\\\\\n",
    "           H(Distance) = \\frac{2}{9}H(1) + \\frac{1}{9}H(2) + \\frac{3}{9}H(3) + \\frac{3}{9}H(4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(1) 1.0\n",
      "H(2) 0\n",
      "H(3) 0.9182958340544896\n",
      "H(4) 0.9182958340544896\n",
      "H(Distance) 0.8344194449252152\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "h_one = (-1/2 * math.log(1/2, 2)) - (1/2 * math.log(1/2, 2))\n",
    "h_two = 0\n",
    "h_three = (-2/3 * math.log(2/3, 2)) - (1/3 * math.log(1/3, 2))\n",
    "h_four = (-1/3 * math.log(1/3, 2)) - (2/3 * math.log(2/3, 2))\n",
    "h_distance = (2/9 * h_one) + (1/9 * h_two) + (3/9 * h_three) + (3/9 * h_four)\n",
    "\n",
    "print(\"H(1)\", h_one)\n",
    "print(\"H(2)\", h_two)\n",
    "print(\"H(3)\", h_three)\n",
    "print(\"H(4)\", h_four)\n",
    "print(\"H(Distance)\", h_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invade $ H(Invade) = \\frac{-5}{9}log_{2}(\\frac{5}{9}) - \\frac{4}{9}log_{2}(\\frac{4}{9})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(Invade) 0.9910760598382222\n"
     ]
    }
   ],
   "source": [
    "h_invade = (-5/9 * math.log(5/9, 2)) - (4/9 * math.log(4/9, 2))\n",
    "print(\"H(Invade)\", h_invade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) $ IG(S, A) = H(S) - H(A) $ where S is the label \"invade\" and A is a given a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG(Technology) 0.07278022578373267\n",
      "IG(Environment) 0.22943684069673975\n",
      "IG(Human) 0.6305080045230521\n",
      "IG(Distance) 0.15665661491300698\n"
     ]
    }
   ],
   "source": [
    "ig_tech = h_invade - h_tech\n",
    "ig_env = h_invade - h_env\n",
    "ig_human = h_invade - h_human\n",
    "ig_distance = h_invade - h_distance\n",
    "\n",
    "print(\"IG(Technology)\", ig_tech)\n",
    "print(\"IG(Environment)\", ig_env)\n",
    "print(\"IG(Human)\", ig_human)\n",
    "print(\"IG(Distance)\", ig_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Based off the information gain, the most optimal feature to construct the root is \"Human\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"aliens.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Using tree above, invade? $ Row 1: Yes\\\\\n",
    "                                Row 2: No\\\\\n",
    "                                Row 3: Yes$\n",
    "                                \n",
    "    Classisifier was correct 2 out of 3 three times, around 67% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3. </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) ME = Majority Error  \n",
    "  \n",
    "Label $ ME(S) = ME(Invade?) = 1 - max(\\frac{5}{9}, \\frac{4}{9}) $\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME(Invade?) 0.444\n"
     ]
    }
   ],
   "source": [
    "me_label = 1 - max(5/9, 4/9)\n",
    "print(\"ME(Invade?)\", round(me_label, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technology $ ME(No) = 1 - max(\\frac{4}{6}, \\frac{2}{6})\\\\  \n",
    "             ME(Yes) = 1 - max(\\frac{1}{3}, \\frac{2}{3})\\\\\n",
    "             ME(Tech) = \\frac{6}{9}ME(No) + \\frac{3}{9}ME(Yes)\\\\ $\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME(Technology) 0.333\n"
     ]
    }
   ],
   "source": [
    "me_no = 1 - max(4/6, 2/6)\n",
    "me_yes = 1 - max(1/3, 2/3)\n",
    "me_tech = (6/9 * me_no) + (3/9 * me_yes)\n",
    "print(\"ME(Technology)\", round(me_tech, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment $ ME(No) = 1 - max(\\frac{1}{4}, \\frac{3}{4})\\\\ \n",
    "              ME(Yes) = 1 - max(\\frac{4}{5}, \\frac{1}{5})\\\\\n",
    "              ME(Environment) = \\frac{4}{9}ME(No) + \\frac{5}{9}ME(Yes)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME(Environment) 0.222\n"
     ]
    }
   ],
   "source": [
    "me_no = 1 - max(1/4, 3/4)\n",
    "me_yes = 1 - max(4/5, 1/5)\n",
    "me_env = (4/9 * me_no) + (5/9 * me_yes)\n",
    "print(\"ME(Environment)\", round(me_env, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human $ ME(Not Care) = 1 - max(\\frac{4}{4}, \\frac{0}{4})\\\\ \n",
    "        ME(Like) = 1 - max(\\frac{1}{4}, \\frac{3}{4})\\\\\n",
    "        ME(Hate) = 1 - max(\\frac{0}{1}, \\frac{1}{1})\\\\\n",
    "        ME(Human) = \\frac{4}{9}ME(Not Care) + \\frac{4}{9}ME(Like) + \\frac{1}{9}ME(Hate)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME(Human) 0.111\n"
     ]
    }
   ],
   "source": [
    "me_notcare = 1 - max(4/4, 0/4)\n",
    "me_like = 1 - max(1/4, 3/4)\n",
    "me_hate = 1 - max(0/1, 1/1)\n",
    "me_human = (4/9 * me_notcare) + (4/9 * me_like) + (1/9 * me_hate)\n",
    "print(\"ME(Human)\", round(me_human, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance $ ME(1) = 1 - max(\\frac{1}{2}, \\frac{1}{2})\\\\ \n",
    "           ME(2) = 1 - max(\\frac{1}{1}, \\frac{0}{1})\\\\\n",
    "           ME(3) = 1 - max(\\frac{2}{3}, \\frac{1}{3})\\\\\n",
    "           ME(4) = 1 - max(\\frac{1}{3}, \\frac{2}{3})\\\\\n",
    "           ME(Distance) = \\frac{2}{9}ME(1) + \\frac{1}{9}ME(2) + \\frac{3}{9}ME(3) + \\frac{3}{9}ME(4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME(Distance) 0.333\n"
     ]
    }
   ],
   "source": [
    "me_one = 1 - max(1/2, 1/2)\n",
    "me_two = 1 - max(1/1, 0/1)\n",
    "me_three = 1 - max(2/3, 1/3)\n",
    "me_four = 1 - max(1/3, 2/3)\n",
    "me_distance = (2/9 * me_one) + (1/9 * me_two) + (3/9 * me_three) + (3/9 * me_four)\n",
    "print(\"ME(Distance)\", round(me_distance, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IG = information gain = H(S) - H(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG(Technology) 0.111\n",
      "IG(Environment) 0.222\n",
      "IG(Human) 0.333\n",
      "IG(Distance) 0.111\n"
     ]
    }
   ],
   "source": [
    "ig_tech = round(me_label - me_tech, 3)\n",
    "ig_env = round(me_label - me_env, 3)\n",
    "ig_human = round(me_label - me_human, 3)\n",
    "ig_distance = round(me_label - me_distance, 3)\n",
    "print(\"IG(Technology)\", ig_tech)\n",
    "print(\"IG(Environment)\", ig_env)\n",
    "print(\"IG(Human)\", ig_human)\n",
    "print(\"IG(Distance)\", ig_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Using majority error, the label \"Human\" will be selected as root attribute. In this case, entropy and majority error will lead to a nearly identitcal tree. However, it is important to notice that majority error calculates a nearly identical information gain for label \"Technology\" and \"Distance\" whereas entropy does not. This will result in a slight difference between the two trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> II. Linear Classifier </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only -1 example (last one) hints at a possible -1 bias term and x<sub>3</sub> with weight 0. Going with this intuition, following equation linear separation is achieved:\n",
    "$  Y = b + w_{1}x_{1} + w_{2}x_{2}+w_{3}x_{3} + w_{4}x_{4}\\\\\n",
    "   Y = -1 + w_{1}x_{1} + w_{2}x_{2}+ 0 + w_{4}x_{4}$\n",
    "   \n",
    "Then w<sub>1</sub>, w<sub>2</sub> w<sub>4</sub> can all be value 1. And results in:\n",
    "\n",
    "$ Y =  -1 + x_{1} + x_{2} + x_{4} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 16 total examples (including the training three). Eight were correct, so accuracy is 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3. </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that our mathematical approach is not sufficient here. Instead, there is another pattern that is apparent with the added data. If the model is thought as m of n. From the last table example two, it indicates that neither x<sub>2</sub> nor x<sub>3</sub> are significant, as they return -1. Instead, one of x<sub>1</sub> or x<sub>4</sub> is needed for the classifier to return 1. This works on every entry on the table. The classifier is as follow:\n",
    "\n",
    "$ x_{1} + x_{4} \\geq 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> III. Experiments </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Source files can be found in this notebook's directory. Implementation of tree is under \"decision_tree.py\" and feature extractor is under \"data.py\". The full source is not pasted here but imported when needed, because reading it in an separate window or IDE would provide a much better experience.\n",
    "\n",
    "Implentation Overview:\n",
    "There is a class \"Tree\" and class \"TreeNode\". Class Tree contain one node which is the root of decision tree. Class tree has classify and depth method, one walks through the tree to reach label and the other finds the maximum depth. The tree is built with \"build_tree\" method which and implements ID3. \n",
    "\n",
    "Below are some decisions made when it comes to the implementation:\n",
    "- <b>Binary Simplification:</b> because this instance lends itself to binary values for both features and label, a binary implementation will be much simpler. It can easily be extended by adding a list as children and some added complexity.\n",
    "- <b> Convert True / False to 0 and 1:</b> continuing with the binary simplification, this helps make indexing the children easy. But on a larger implementation, this hardcoding should be avoided.\n",
    "- <b> Code Design:</b> the code does not follow object oriented implementation to the fullest. There are many helper functions such as those that calculate information gain or retrive subsets. Those are outside of the tree class, so is the node. The decision tree class provides a simplification of the interface, so user would only have to run build and classify and ignore details such as creating individual nodes. However, the style can be greatly improved and code organization would help readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)  \n",
    "1. Does the name contain a dot?\n",
    "2. Are the parity of the length of first and last name different? (i.e. cannot be both even or odd)\n",
    "3. Is the length of the name over seven characters?\n",
    "4. Are there more vowels than consonants?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) and (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: 0.252\n",
      "Test Error: 0.65\n"
     ]
    }
   ],
   "source": [
    "from data import extract\n",
    "from decision_tree import *\n",
    "\n",
    "\n",
    "train_data = extract(\"data/training.data\")\n",
    "test_data = extract(\"data/test.data\")\n",
    "tree = Tree(train_data, True)\n",
    "\n",
    "train_error_count = 0\n",
    "for instance in train_data:\n",
    "    predict = tree.classify(instance)\n",
    "    if predict != instance[-1]:\n",
    "        train_error_count += 1\n",
    "        \n",
    "test_error_count = 0\n",
    "for instance in test_data:\n",
    "    predict = tree.classify(instance)\n",
    "    if predict != instance[-1]:\n",
    "        test_error_count += 1\n",
    "\n",
    "\n",
    "print(\"Train Error:\", round(train_error_count / len(train_data), 3))\n",
    "print(\"Test Error:\", round(test_error_count / len(test_data), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Depth is computed below with the member method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Max depth:\", tree.depth())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)  Max depth is 5, so here cross validation is done on tree of depth from 1 to 5. Depth 3 should be chosen as best because it has the lowest cross validated error by far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 1 standard deviation: 0.02\n",
      "Depth = 1: 0.365\n",
      "Depth 2 standard deviation: 0.019\n",
      "Depth = 2: 0.154\n",
      "Depth 3 standard deviation: 0.022\n",
      "Depth = 3: 0.147\n",
      "Depth 4 standard deviation: 0.046\n",
      "Depth = 4: 0.22\n",
      "Depth 5 standard deviation: 0.046\n",
      "Depth = 5: 0.22\n"
     ]
    }
   ],
   "source": [
    "part_a = extract('data/folds/training-00.data')\n",
    "part_b = extract('data/folds/training-01.data')\n",
    "part_c = extract('data/folds/training-02.data')\n",
    "part_d = extract('data/folds/training-03.data')\n",
    "partitions = []\n",
    "partitions.append(part_a)\n",
    "partitions.append(part_b)\n",
    "partitions.append(part_c)\n",
    "partitions.append(part_d)\n",
    "print(\"Depth = 1:\", cross_validate(partitions, True, 1))\n",
    "print(\"Depth = 2:\", cross_validate(partitions, True, 2))\n",
    "print(\"Depth = 3:\", cross_validate(partitions, True, 3))\n",
    "print(\"Depth = 4:\", cross_validate(partitions, True, 4))\n",
    "print(\"Depth = 5:\", cross_validate(partitions, True, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) The error rate increased, meaning worse accuracy despite the indication of low cross validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 0.717\n"
     ]
    }
   ],
   "source": [
    "pruned_tree = Tree(train_data, True, 3)\n",
    "\n",
    "test_error_count = 0\n",
    "for instance in test_data:\n",
    "    predict = pruned_tree.classify(instance)\n",
    "    if predict != instance[-1]:\n",
    "        test_error_count += 1\n",
    "\n",
    "print(\"Test Error:\", round(test_error_count / len(test_data), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Compared to original tree, the depth limited tree did not perform better. Because the full tree is only of depth 5, reducing it to depth 3 was most likely detrimental. There is a trade off when it comes to limiting depth. A tree too tall will imply overfitting the data. However, pruning the tree comes at a cost of discarding a subranch. Not to mention, trees to short will not cover all the possile scenarios. Thus limiting depth is not necessary a bad idea, but more of an option that requires tradeoff considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> IV. Decision Lists </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hunch: Linear Threshold functions are linearly separable. If decision lists can be shown to be a subset of linear threshold functions, then they are linearly separable as well.\n",
    "\n",
    "Proof: 1-Decision Lists are a subset of Linear Threshold Functions\n",
    "\n",
    "A 1-Decision List is defined as following:\n",
    "- each box contains one boolean variable, possible negated\n",
    "- each box can either return $ ( 0, 1 ) $ or move to another box\n",
    "\n",
    "General form of a linear threshold function:\n",
    "$ w_{1}x_{1} + w_{2}x_{2} ... w_{n}x_{n} \\geq b $ \n",
    "\n",
    "\n",
    "\n",
    "Then the objective is to find weight vector and bias for all 1-decision lists. Observe that all 1-decision lists are equivalent to a combination of disjunction or conjunction of single variables (negated possibly). This is a simple boolean statement and can be linearly separated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
